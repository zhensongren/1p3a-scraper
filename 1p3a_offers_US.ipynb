{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the post information from offer section of \"1p3a.com\"\n",
    "1. Read data from old csv data file to save the  most recent post date and its id historical data\n",
    "2. Request html page with url sorted by post time from page 1 to page X(default: 10).\n",
    "    1. scrape the whole page\n",
    "        if id and dates new:\n",
    "            save the info to temp variable\n",
    "        else(=last most recent post ID):\n",
    "            break the whole scraping script\n",
    "3. Insert the new data to the front of the csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Chrome webdriver and specify the page url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "START_URL = \"https://www.1point3acres.com/bbs/forum.php?mod=forumdisplay&fid=237&orderby=dateline&sortid=320&orderby=dateline&sortid=320&filter=author&page=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the previous scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the 1st row to save the previous most recent id and date\n",
    "try:\n",
    "    old_df = pd.read_csv('offers_US.csv', nrows=1)\n",
    "    latest_id_from_CSV = old_df['post_id'][0] # Get the most recent post's ID of historical data\n",
    "    latest_date_from_CSV = pd.to_datetime(old_df['Date'][0])  # Get the most recent post's date of historical data\n",
    "except:\n",
    "    latest_id_from_CSV = 0\n",
    "    latest_date_from_CSV = pd.to_datetime('1900-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to find and clean data\n",
    "def get_date(p):\n",
    "    try:\n",
    "        date_span = p.find('td', class_='by').find('em').find('span')\n",
    "        if date_span.find('span'):\n",
    "            date = date_span.find('span')['title']\n",
    "        else: \n",
    "            date = date_span.text\n",
    "    except:\n",
    "          date = 'NA'\n",
    "    else:\n",
    "        date = pd.to_datetime(date)\n",
    "    return date\n",
    "        \n",
    "def get_poster(p):\n",
    "    try:\n",
    "        poster = p.find('td', class_='by').find('cite').find('a').text\n",
    "    except:\n",
    "        poster = \"NA\"\n",
    "    return poster\n",
    "\n",
    "def get_reply_num(p):\n",
    "    try:\n",
    "        reply = int(p.find('a', class_='xi2').text)\n",
    "    except: \n",
    "        reply = -1\n",
    "    return reply\n",
    "\n",
    "def get_view_num(p):\n",
    "    try:\n",
    "        view = int(p.find('a', class_='xi2').parent.find('em').text)\n",
    "    except:\n",
    "        view = -1\n",
    "    return view\n",
    "\n",
    "def get_post_id(p):\n",
    "    try:\n",
    "        post_id = int(p['id'].split('_')[1])\n",
    "    except:\n",
    "        post_id = -1\n",
    "    return post_id\n",
    "\n",
    "def get_post_title(p):\n",
    "    try:\n",
    "        post_title = p.find('a', class_=\"s xst\").text\n",
    "    except:\n",
    "        post_title = 'NA'\n",
    "        \n",
    "    return post_title\n",
    "\n",
    "def get_company(p):\n",
    "    try:\n",
    "        company = p.find('font', {\"color\": \"#FF6600\"}).text\n",
    "    except:\n",
    "        company = 'NA'\n",
    "    return company\n",
    "\n",
    "def get_experience(p):\n",
    "    try:\n",
    "        experience = p.find('font', {\"color\": \"#00B2E8\"}).text\n",
    "    except:\n",
    "        experience = 'NA'\n",
    "    return experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape post post by post and then page by page. Default maximal number of pages is 10\n",
    "def get_referrals(driver, START_URL, max_page_num=10, latest_id_from_CSV=None, latest_date_from_CSV=None):   \n",
    "    refers = []\n",
    "    get_next_page = True\n",
    "    # scrape the data from the page 1 to max_page_num(default: 10)\n",
    "    i = 1\n",
    "    while i<=max_page_num and get_next_page:\n",
    "        url = START_URL + str(i)\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        posts = soup.find_all('tbody', id=re.compile(\"normalthread_\")) \n",
    "#         print(f'{len(posts)} posts to be scraped')\n",
    "        # get list of referral data for each page\n",
    "        for p in posts:\n",
    "\n",
    "            # Date\n",
    "            date = get_date(p)\n",
    "\n",
    "            # Poster. 有匿名用户。\n",
    "            poster = get_poster(p)\n",
    "\n",
    "            # 回复\n",
    "            reply = get_reply_num(p)\n",
    "            # 查看\n",
    "            view = get_view_num(p)\n",
    "\n",
    "            # post id\n",
    "            post_id = get_post_id(p)\n",
    "\n",
    "            # Check if the post already saved.   \n",
    "            if  post_id==latest_id_from_CSV:\n",
    "                get_next_page = False\n",
    "                break   \n",
    "\n",
    "            # post_title\n",
    "            post_title = get_post_title(p)\n",
    "            # company\n",
    "            company = get_company(p)\n",
    "            # experience\n",
    "            experience = get_experience(p)\n",
    "            post_dict = {'Date': date, 'Poster': poster, 'Replies': reply, 'Views': view, 'post_id':post_id, 'post_title':post_title,'company':company, 'experience':experience}\n",
    "#             print(post_dict)\n",
    "#             print('--'*20)\n",
    "            refers.append(post_dict)\n",
    "        # set the next page\n",
    "        i+=1\n",
    "    return refers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "refers = get_referrals(driver, START_URL, max_page_num=235, \n",
    "                       latest_id_from_CSV=latest_id_from_CSV, latest_date_from_CSV=latest_date_from_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all the data to local CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert the new data to the front of the csv file.\n",
    "# def init_csv_file(file_path, field_names):\n",
    "#     with open(file_path, 'w', newline='', encoding='utf8') as csv_file:\n",
    "#         writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "#         writer.writeheader()\n",
    "        \n",
    "# def write_to_csv(file_path, field_names, data):\n",
    "#     with open(file_path, 'a', newline='', encoding='utf8') as csv_file:\n",
    "#         writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "#         writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_names = ['Date', 'Poster', 'Replies', 'Views', 'post_id', 'post_title', 'experience']\n",
    "\n",
    "# #initialize the file for the 1st scrpae\n",
    "# init_csv_file('./referral_US.csv', field_names=field_names)\n",
    "# #Add new data to existing file\n",
    "# write_to_csv('./referral_US.csv', field_names=field_names, data=refers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower level of handling saving new data.\n",
    "def insert_into_csv(file_path, data):\n",
    "    with open(file_path, 'r', newline='', encoding='utf8') as csv_file:\n",
    "        text = csv_file.readlines()\n",
    "        new_data = []\n",
    "        for row_num in range(len(refers)):\n",
    "            row = ','.join([str(value) for value in data[row_num].values()])+'\\n'\n",
    "            new_data.append(row)\n",
    "        # Use slice assignment to insert a list to the first row.\n",
    "        text[0:0] = new_data\n",
    "        print(text[0])\n",
    "        \n",
    "    with open(file_path, 'w', newline='', encoding='utf8') as csv_file:\n",
    "        csv_file.writelines(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert_into_csv('./referral_US.csv', data=refers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the new batch data to the front of the csv file. Posts in CSV file are sorted by post time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always save the new data just below the header row.\n",
    "def insert_data(file_path, data):\n",
    "    # Save the old data and headers\n",
    "    with open(file_path, 'r', newline='', encoding='utf8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        if reader.fieldnames is None:\n",
    "            reader.fieldnames = list(data[0].keys())\n",
    "            \n",
    "        old_data = []\n",
    "        for row in reader:\n",
    "            old_data.append(row)\n",
    "            \n",
    "    with open(file_path, 'w', newline='', encoding='utf8') as csv_file:\n",
    "    # Write the header and the new data                        \n",
    "        writer = csv.DictWriter(csv_file, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "        \n",
    "    # Append the old data \n",
    "    with open(file_path, 'a', newline='', encoding='utf8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=reader.fieldnames)\n",
    "        writer.writerows(old_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_data('./offers_US.csv', data=refers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved CSV and check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('offers_US.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Views</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>687976</td>\n",
       "      <td>Qualtrics莫名其妙跳楼包</td>\n",
       "      <td>Qualtrics</td>\n",
       "      <td>博士+(1-3年)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-15 00:00:00</td>\n",
       "      <td>kankanjiukankan</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>687929</td>\n",
       "      <td>条纹最新调整offer结构包</td>\n",
       "      <td>stripe</td>\n",
       "      <td>硕士+(5-10年)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>687845</td>\n",
       "      <td>McKinsey QB DE</td>\n",
       "      <td>McKinsey</td>\n",
       "      <td>硕士+(1-3年)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>687839</td>\n",
       "      <td>Roblox NG 标准包</td>\n",
       "      <td>Roblox</td>\n",
       "      <td>硕士+(fresh grad 无实习或全职)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-14 00:00:00</td>\n",
       "      <td>jackzhang1990</td>\n",
       "      <td>24</td>\n",
       "      <td>2245</td>\n",
       "      <td>687810</td>\n",
       "      <td>Facebook E5大包</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>硕士+(5-10年)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date           Poster  Replies  Views  post_id  \\\n",
       "0  2020-11-15 00:00:00              NaN        0     89   687976   \n",
       "1  2020-11-15 00:00:00  kankanjiukankan        1    211   687929   \n",
       "2  2020-11-14 00:00:00              NaN        0    104   687845   \n",
       "3  2020-11-14 00:00:00              NaN        1    178   687839   \n",
       "4  2020-11-14 00:00:00    jackzhang1990       24   2245   687810   \n",
       "\n",
       "         post_title    company              experience  \n",
       "0  Qualtrics莫名其妙跳楼包  Qualtrics               博士+(1-3年)  \n",
       "1    条纹最新调整offer结构包     stripe              硕士+(5-10年)  \n",
       "2    McKinsey QB DE   McKinsey               硕士+(1-3年)  \n",
       "3     Roblox NG 标准包     Roblox  硕士+(fresh grad 无实习或全职)  \n",
       "4     Facebook E5大包   Facebook              硕士+(5-10年)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8839, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
