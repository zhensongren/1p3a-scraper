{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Data Science interview section. Get the 'Date','post_id', 'post_title', 'company', 'Poster', 'Replies', 'Views' from referral section of \"1p3a.com\"\n",
    "1. Read data from old csv data file to the the current newest post date and its id\n",
    "2. Request html from page 1 to page X.\n",
    "    1. scrape the whole page\n",
    "        if id and dates new:\n",
    "            save the info to temp variable\n",
    "        else:\n",
    "        break the whole scraping script\n",
    "3. append the new data to the front of the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "START_URL = \"https://www.1point3acres.com/bbs/forum.php?mod=forumdisplay&fid=259&orderby=dateline&sortid=311&filter=author&orderby=dateline&sortid=311&page=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the previous scrpaed info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the 1st row to the previous most recent id and date\n",
    "try:\n",
    "    old_df = pd.read_csv('interview_DS_US.csv', nrows=1)\n",
    "    latest_id_from_CSV = old_df['post_id'][0]\n",
    "    latest_date_from_CSV = pd.to_datetime(old_df['Date'][0])\n",
    "except:\n",
    "    latest_id_from_CSV = 0\n",
    "    latest_date_from_CSV = pd.to_datetime('1900-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(p):\n",
    "    try:\n",
    "        date_span = p.find('td', class_='by').find('em').find('span')\n",
    "        if date_span.find('span'):\n",
    "            date = date_span.find('span')['title']\n",
    "        else: \n",
    "            date = date_span.text\n",
    "    except:\n",
    "          date = 'NA'\n",
    "    else:\n",
    "        date = pd.to_datetime(date)\n",
    "    return date\n",
    "        \n",
    "def get_poster(p):\n",
    "    try:\n",
    "        poster = p.find('td', class_='by').find('cite').find('a').text\n",
    "    except:\n",
    "        poster = \"NA\"\n",
    "    return poster\n",
    "\n",
    "def get_reply_num(p):\n",
    "    try:\n",
    "        reply = int(p.find('a', class_='xi2').text)\n",
    "    except: \n",
    "        reply = -1\n",
    "    return reply\n",
    "\n",
    "def get_view_num(p):\n",
    "    try:\n",
    "        view = int(p.find('a', class_='xi2').parent.find('em').text)\n",
    "    except:\n",
    "        view = -1\n",
    "    return view\n",
    "\n",
    "def get_post_id(p):\n",
    "    try:\n",
    "        post_id = int(p['id'].split('_')[1])\n",
    "    except:\n",
    "        post_id = -1\n",
    "    return post_id\n",
    "\n",
    "def get_post_title(p):\n",
    "    try:\n",
    "        post_title = p.find('a', class_=\"s xst\").text\n",
    "    except:\n",
    "        post_title = 'NA'\n",
    "        \n",
    "    return post_title\n",
    "def get_company(p):\n",
    "    try:\n",
    "        company = p.find('font', {\"color\": \"#FF6600\"}).text\n",
    "    except:\n",
    "        company = 'NA'\n",
    "    return company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_referrals(driver, START_URL, max_page_num=10, latest_id_from_CSV=None, latest_date_from_CSV=None):   \n",
    "    refers = []\n",
    "    get_next_page = True\n",
    "    # scrape the data from the page 1 to 50\n",
    "    i = 1\n",
    "    while i<=max_page_num and get_next_page:\n",
    "        url = START_URL + str(i)\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        posts = soup.find_all('tbody', id=re.compile(\"normalthread_\")) \n",
    "#         print(f'{len(posts)} posts to be scraped')\n",
    "        # get list of referral data for each page\n",
    "        for p in posts:\n",
    "\n",
    "            # Date\n",
    "            date = get_date(p)\n",
    "\n",
    "            # Poster. 有匿名用户。\n",
    "            poster = get_poster(p)\n",
    "\n",
    "            # 回复\n",
    "            reply = get_reply_num(p)\n",
    "            # 查看\n",
    "            view = get_view_num(p)\n",
    "\n",
    "            # post id\n",
    "            post_id = get_post_id(p)\n",
    "\n",
    "            # Check if the post already saved.   \n",
    "            if  post_id==latest_id_from_CSV:\n",
    "                get_next_page = False\n",
    "                break   \n",
    "\n",
    "            # post_title\n",
    "            post_title = get_post_title(p)\n",
    "            # company\n",
    "            company = get_company(p)\n",
    "            post_dict = {'Date': date, 'Poster': poster, 'Replies': reply, 'Views': view, 'post_id':post_id, 'post_title':post_title, 'company':company}\n",
    "#             print(post_dict)\n",
    "#             print('--'*20)\n",
    "            refers.append(post_dict)\n",
    "        # set the next page\n",
    "        i+=1\n",
    "    return refers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "refers = get_referrals(driver, START_URL, max_page_num=206, \n",
    "                       latest_id_from_CSV=latest_id_from_CSV, latest_date_from_CSV=latest_date_from_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all the data to local CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert the new data to the front of the csv file.\n",
    "# def init_csv_file(file_path, field_names):\n",
    "#     with open(file_path, 'w', newline='', encoding='utf8') as csv_file:\n",
    "#         writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "#         writer.writeheader()\n",
    "        \n",
    "# def write_to_csv(file_path, field_names, data):\n",
    "#     with open(file_path, 'a', newline='', encoding='utf8') as csv_file:\n",
    "#         writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "#         writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_names = ['Date', 'Poster', 'Replies', 'Views', 'post_id', 'post_title', 'company']\n",
    "\n",
    "# #initialize the file for the 1st scrpae\n",
    "# init_csv_file('./referral_US.csv', field_names=field_names)\n",
    "# #Add new data to existing file\n",
    "# write_to_csv('./referral_US.csv', field_names=field_names, data=refers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower level of handling saving new data.\n",
    "def insert_into_csv(file_path, data):\n",
    "    with open(file_path, 'r', newline='', encoding='utf8') as csv_file:\n",
    "        text = csv_file.readlines()\n",
    "        new_data = []\n",
    "        for row_num in range(len(refers)):\n",
    "            row = ','.join([str(value) for value in data[row_num].values()])+'\\n'\n",
    "            new_data.append(row)\n",
    "        # Use slice assignment to insert a list to the first row.\n",
    "        text[0:0] = new_data\n",
    "        print(text[0])\n",
    "        \n",
    "    with open(file_path, 'w', newline='', encoding='utf8') as csv_file:\n",
    "        csv_file.writelines(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert_into_csv('./referral_US.csv', data=refers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always save the new data just below the header row.\n",
    "def insert_data(file_path, data):\n",
    "    # Save the old data and headers\n",
    "    with open(file_path, 'r', newline='', encoding='utf8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        if reader.fieldnames is None:\n",
    "            reader.fieldnames = list(data[0].keys())\n",
    "            \n",
    "        old_data = []\n",
    "        for row in reader:\n",
    "            old_data.append(row)\n",
    "            \n",
    "    with open(file_path, 'w', newline='', encoding='utf8') as csv_file:\n",
    "    # Write the header and the new data                        \n",
    "        writer = csv.DictWriter(csv_file, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "        \n",
    "    # Append the old data \n",
    "    with open(file_path, 'a', newline='', encoding='utf8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=reader.fieldnames)\n",
    "        writer.writerows(old_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_data('./interview_DS_US.csv', data=refers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the saved CSV and check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('interview_DS_US.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Views</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>687935</td>\n",
       "      <td>斯伦贝谢 DS Intern</td>\n",
       "      <td>Schlumberger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-15 00:00:00</td>\n",
       "      <td>sinkinx</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>687913</td>\n",
       "      <td>JPMorgan OA原题 2021 Applied AI and Machine Lear...</td>\n",
       "      <td>JPMorgan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>687873</td>\n",
       "      <td>亚麻 applied scientist Alexa AI</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-14 00:00:00</td>\n",
       "      <td>harryiori</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>687759</td>\n",
       "      <td>Altice USA 面经</td>\n",
       "      <td>Altice USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "      <td>687748</td>\n",
       "      <td>fb dsa timeline（无面经）分享</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date     Poster  Replies  Views  post_id  \\\n",
       "0  2020-11-15 00:00:00        NaN        0    107   687935   \n",
       "1  2020-11-15 00:00:00    sinkinx        0     72   687913   \n",
       "2  2020-11-15 00:00:00        NaN        0    115   687873   \n",
       "3  2020-11-14 00:00:00  harryiori        0    106   687759   \n",
       "4  2020-11-14 00:00:00        NaN        4    337   687748   \n",
       "\n",
       "                                          post_title       company  \n",
       "0                                     斯伦贝谢 DS Intern  Schlumberger  \n",
       "1  JPMorgan OA原题 2021 Applied AI and Machine Lear...      JPMorgan  \n",
       "2                      亚麻 applied scientist Alexa AI        Amazon  \n",
       "3                                      Altice USA 面经    Altice USA  \n",
       "4                             fb dsa timeline（无面经）分享      Facebook  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7598, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          object\n",
       "Poster        object\n",
       "Replies        int64\n",
       "Views          int64\n",
       "post_id        int64\n",
       "post_title    object\n",
       "company       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
